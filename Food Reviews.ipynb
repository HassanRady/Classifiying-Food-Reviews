{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import re\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,LSTM,Embedding,Flatten,SimpleRNN\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer,text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rate\n",
       "0  I have bought several of the Vitality canned d...     5\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...     1\n",
       "2  This is a confection that has been around a fe...     4\n",
       "3  If you are looking for the secret ingredient i...     2\n",
       "4  Great taffy at a great price.  There was a wid...     5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the csv file\n",
    "df = pd.read_csv(\"Reviews.csv\")\n",
    "df.head()\n",
    "\n",
    "# we need only the text and score\n",
    "df = df.loc[:,(\"Text\",'Score')]\n",
    "# remove all repeated reviews\n",
    "df.drop_duplicates(subset=['Text','Score'],keep='first',inplace=True)\n",
    "df.shape\n",
    "\n",
    "# changing names\n",
    "df['review'] = df['Text']\n",
    "df['rate'] = df['Score']\n",
    "df.drop(['Text',\"Score\"],axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  I have bought several of the Vitality canned d...          1\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...          0\n",
       "2  This is a confection that has been around a fe...          1\n",
       "3  If you are looking for the secret ingredient i...          0\n",
       "4  Great taffy at a great price.  There was a wid...          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dividing the rating to good above 3 and bad below 3\n",
    "def mark_sent(rate):\n",
    "    if rate > 3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['sentiment'] = df['rate'].apply(mark_sent)\n",
    "df.drop(['rate'],inplace=True,axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    306819\n",
       "0     86856\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing number of reviews for each class\n",
    "df[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(393675, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I got a wild hair for taffy and ordered this f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This saltwater taffy had great flavors and was...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  I have bought several of the Vitality canned d...          1\n",
       "1  This is a confection that has been around a fe...          1\n",
       "2  Great taffy at a great price.  There was a wid...          1\n",
       "3  I got a wild hair for taffy and ordered this f...          1\n",
       "4  This saltwater taffy had great flavors and was...          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balancing the data \n",
    "# i didn't balance the data because i found the accuracy better and there is no enough data\n",
    "good_df =df.loc[df.sentiment == 1,:][:]\n",
    "bad_df = df.loc[df.sentiment == 0,:][:]\n",
    "\n",
    "df = pd.concat([good_df,bad_df],ignore_index=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(393675, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have used Fresh 'N Clean on my show cats for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this product was purchased for my husband who ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought i was purchasing something different...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do you enjoy nougats?  Are you a fan of cinnam...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A pack of 12 is a huge amount of noodles. They...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  I have used Fresh 'N Clean on my show cats for...          1\n",
       "1  this product was purchased for my husband who ...          1\n",
       "2  i thought i was purchasing something different...          1\n",
       "3  Do you enjoy nougats?  Are you a fan of cinnam...          1\n",
       "4  A pack of 12 is a huge amount of noodles. They...          1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffling the data\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = df\n",
    "\n",
    "reviews = data_df.iloc[:,0].values\n",
    "y_data = data_df.iloc[:,1].values\n",
    "trainset = reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting every review in token\n",
    "tokens = []\n",
    "tokens = [word_tokenize(str(sent)) for sent in reviews]\n",
    "\n",
    "# replacing all non characters by space then splitting the sentences into words\n",
    "words = []\n",
    "for sent in tokens:\n",
    "    s = re.sub(\"[^A-Za-z]\",\" \",str(sent))\n",
    "    word = re.split(\"\\s\",s)\n",
    "    words.append(word)\n",
    "\n",
    "# removing all spaces from words list    \n",
    "for word in words:\n",
    "    while '' in word:\n",
    "        word.remove('')\n",
    "        \n",
    "lower_case = []\n",
    "for i in words:\n",
    "    x = [word.lower() for word in i]\n",
    "    lower_case.append(x)\n",
    "\n",
    "# taking the root of every word\n",
    "lemmatized = []\n",
    "for words in lower_case:\n",
    "    x = [WordNetLemmatizer().lemmatize(word) for word in words]\n",
    "    lemmatized.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all stopwords\n",
    "# I didn't remove the stop words because people sometimes say about something which is bad \"not good\" for example \n",
    "# so \"not\" here is a stop word if i did remove it the review will be \"good\" \n",
    "stopwords = set(stopwords.words('english'))\n",
    "filterd_words = []\n",
    "for words in lemmatized:\n",
    "    x = [word for word in words] #if word not in stopwords]   \n",
    "    filterd_words.append(x)                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking words that are bigger than 2    \n",
    "filterd = []\n",
    "for words in filterd_words:\n",
    "    x = [word for word in words if len(word) >= 2]\n",
    "    filterd.append(x)\n",
    "\n",
    "# converting words into vectors\n",
    "model_word2vec = Word2Vec(filterd)\n",
    "model_word2vec.train(filterd,epochs=10,total_examples=len(filterd))\n",
    "words_vector = model_word2vec.wv\n",
    "vocab = words_vector.vocab.items()\n",
    "\n",
    "embedd_matrix = words_vector.vectors\n",
    "word2id = {key:value.index for key,value in vocab}\n",
    "\n",
    "# unknown words\n",
    "UNKs = 0\n",
    "UNK_index = 0\n",
    "UNK_token = 'UNK'\n",
    "UNK_vector = np.mean(embedd_matrix,axis=0)\n",
    "\n",
    "embedd_matrix = np.insert(embedd_matrix,[UNK_index],[UNK_vector],axis=0)\n",
    "word2id = {word:(index+1) if index >= UNK_index else index for word,index in word2id.items()}\n",
    "word2id[UNK_token] = UNK_index\n",
    "\n",
    "sequences = []\n",
    "for sent in filterd:\n",
    "    x = []\n",
    "    for word in sent:\n",
    "        if word in word2id:\n",
    "            x.append(word2id.get(word))\n",
    "        else:\n",
    "            x.append(UNK_index)\n",
    "            UNKs+=1\n",
    "    sequences.append(x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding each review to be consistent\n",
    "data = pad_sequences(sequences,maxlen=300,padding='post',dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoded\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "Y = to_categorical(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way to prepare the data \n",
    "train_temp = []\n",
    "for sentence in trainset:\n",
    "    train_temp.append(text_to_word_sequence(str(sentence),filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                                            lower=True,split=\" \"))\n",
    "filtered_temp = []\n",
    "for sentence in train_temp:\n",
    "    w = [word for word in sentence]\n",
    "    filtered_temp.append(w)\n",
    "\n",
    "x = []\n",
    "for sentence in filtered_temp:\n",
    "    z = []\n",
    "    for word in sentence:\n",
    "        if word in word2id and len(word) > 2:\n",
    "            z.append(word2id.get(word))\n",
    "        else:\n",
    "            z.append(UNK_index)\n",
    "            UNKs+=1\n",
    "    x.append(z)\n",
    "temp_data = pad_sequences(x,maxlen=300,padding='post',dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate decay\n",
    "def lr_scheduler(epoch, lr):\n",
    "    decay_rate = 0.1\n",
    "    decay_step = 90\n",
    "    if epoch % decay_step == 0 and epoch:\n",
    "        return lr * decay_rate\n",
    "    return lr\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 300, 100)          3154900   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 300, 80)           57920     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 24000)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                384016    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,596,853\n",
      "Trainable params: 3,596,853\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# spliting the data into train and validation\n",
    "x_train,x_val,y_train,y_val = train_test_split(data,y_data,test_size=0.1,random_state=42,shuffle=True)\n",
    "\n",
    "input_dims = len(embedd_matrix)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=input_dims,output_dim=100,input_length=300,weights=[embedd_matrix]))\n",
    "model.add(LSTM(80,activation='tanh',return_sequences=True))\n",
    "# model.add(LSTM(64,activation='tanh'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16,activation='tanh'))\n",
    "# model.add(Dropout(0.4))\n",
    "# model.add(Dense(8,activation='tanh'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducing the learning rate over plateau\n",
    "from tensorflow.keras.callbacks import *\n",
    "reduce_lr = ReduceLROnPlateau(montor='val_loss',patience=2,mode='auto',verbose=1,factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 354307 samples, validate on 39368 samples\n",
      "Epoch 1/10\n",
      "354307/354307 [==============================] - 531s 1ms/sample - loss: 0.2417 - accuracy: 0.9002 - val_loss: 0.2228 - val_accuracy: 0.9078\n",
      "Epoch 2/10\n",
      "354307/354307 [==============================] - 518s 1ms/sample - loss: 0.2010 - accuracy: 0.9193 - val_loss: 0.2060 - val_accuracy: 0.9170\n",
      "Epoch 3/10\n",
      "354307/354307 [==============================] - 521s 1ms/sample - loss: 0.1848 - accuracy: 0.9263 - val_loss: 0.2067 - val_accuracy: 0.9185\n",
      "Epoch 4/10\n",
      "354304/354307 [============================>.] - ETA: 0s - loss: 0.1730 - accuracy: 0.9322 ETA: 0s - loss: 0.1730 - accuracy: 0.\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "354307/354307 [==============================] - 510s 1ms/sample - loss: 0.1730 - accuracy: 0.9322 - val_loss: 0.2067 - val_accuracy: 0.9173\n",
      "Epoch 5/10\n",
      "202624/354307 [================>.............] - ETA: 3:30 - loss: 0.1528 - accuracy: 0.9408"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "start = time.time()\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "trained_model = model.fit(x_train,y_train,epochs=epochs,batch_size=batch_size,shuffle=True,\n",
    "                          validation_data=(x_val,y_val),callbacks=[reduce_lr])\n",
    "end = time.time() - start\n",
    "print(\"Totla Time: {:.3f}min\".format(end/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting the loss and accuarcy for the training and validation phase\n",
    "train_acc = trained_model.history['accuracy']\n",
    "train_loss = trained_model.history['loss']\n",
    "val_acc = trained_model.history['val_accuracy']\n",
    "val_loss = trained_model.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(range(epochs),train_loss,label='train_loss')\n",
    "plt.plot(range(epochs),val_loss,label='val_loss')\n",
    "plt.title('loss')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(epochs),train_acc,label='train_accuracy')\n",
    "plt.plot(range(epochs),val_acc,label='val_accuracy')\n",
    "plt.title('accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
